{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYlsTRPjazIG",
        "outputId": "bb0ff6f0-aa1e-426f-9c76-b15e9f07d7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted: ['crop_yield.csv']\n",
            "Dataset preview:\n",
            "           Crop  Crop_Year       Season  State     Area  Production  \\\n",
            "0      Arecanut       1997  Whole Year   Assam  73814.0       56708   \n",
            "1     Arhar/Tur       1997  Kharif       Assam   6637.0        4685   \n",
            "2   Castor seed       1997  Kharif       Assam    796.0          22   \n",
            "3      Coconut        1997  Whole Year   Assam  19656.0   126905000   \n",
            "4  Cotton(lint)       1997  Kharif       Assam   1739.0         794   \n",
            "\n",
            "   Annual_Rainfall  Fertilizer  Pesticide        Yield  \n",
            "0           2051.4  7024878.38   22882.34     0.796087  \n",
            "1           2051.4   631643.29    2057.47     0.710435  \n",
            "2           2051.4    75755.32     246.76     0.238333  \n",
            "3           2051.4  1870661.52    6093.36  5238.051739  \n",
            "4           2051.4   165500.63     539.09     0.420909  \n",
            "\n",
            "After cleaning: (19689, 10)\n",
            "\n",
            " Linear Regression\n",
            "MAE : 63.884930308847856\n",
            "RMSE: 389.6808093285026\n",
            "R²  : 0.8104798078459079\n",
            "----------------------------------------\n",
            "\n",
            " Random Forest\n",
            "MAE : 10.313753545514562\n",
            "RMSE: 125.73049663950972\n",
            "R²  : 0.9802703803473016\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# 2. Unzip Dataset\n",
        "zip_path = \"/archive.zip\"\n",
        "extract_path = \"data\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Files extracted:\", os.listdir(extract_path))\n",
        "\n",
        "# 3. Load CSV File\n",
        "csv_file = os.listdir(extract_path)[0]  # assumes one CSV inside zip\n",
        "data = pd.read_csv(os.path.join(extract_path, csv_file))\n",
        "\n",
        "print(\"Dataset preview:\")\n",
        "print(data.head())\n",
        "\n",
        "# 4. Basic Cleaning\n",
        "data = data.dropna()  # simple & acceptable\n",
        "print(\"\\nAfter cleaning:\", data.shape)\n",
        "\n",
        "# 5. Separate Features & Target\n",
        "X = data.drop('Yield', axis=1)\n",
        "y = data['Yield']\n",
        "\n",
        "# 6. Identify Column Types\n",
        "categorical_cols = ['Crop', 'Season', 'State']\n",
        "numerical_cols = [\n",
        "    'Crop_Year',\n",
        "    'Area',\n",
        "    'Annual_Rainfall',\n",
        "    'Fertilizer',\n",
        "    'Pesticide'\n",
        "]\n",
        "\n",
        "# 7. Preprocessing Pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 8. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 9. Models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Random Forest\": RandomForestRegressor(\n",
        "        n_estimators=120,\n",
        "        max_depth=10,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# 10. Training & Evaluation\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessing', preprocessor),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    predictions = pipeline.predict(X_test)\n",
        "\n",
        "    print(\"\\n\", name)\n",
        "    print(\"MAE :\", mean_absolute_error(y_test, predictions))\n",
        "\n",
        "    rmse = mean_squared_error(y_test, predictions) ** 0.5\n",
        "    print(\"RMSE:\", rmse)\n",
        "\n",
        "    print(\"R²  :\", r2_score(y_test, predictions))\n",
        "    print(\"-\" * 40)"
      ]
    }
  ]
}